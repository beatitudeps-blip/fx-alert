"""
V4çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆã¿ã‚“ãªã®FXå¯¾å¿œï¼‰

run_idã§å‡ºåŠ›ã‚’åˆ†é›¢:
results/{run_id}/{symbol}/
  â”œâ”€â”€ summary.json
  â”œâ”€â”€ trades.csv
  â”œâ”€â”€ fills.csv
  â”œâ”€â”€ equity_curve.csv
  â””â”€â”€ skipped_signals.csv
"""
import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.env_check import load_dotenv_if_exists, check_api_key
from src.backtest_v4_integrated import run_backtest_v4_integrated
from src.config_loader import load_broker_config
from src.metrics_v3 import calculate_metrics_v3, trades_to_dataframe, fills_to_dataframe
import pandas as pd

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
load_dotenv_if_exists()


def main():
    parser = argparse.ArgumentParser(description="V4çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    parser.add_argument("--config", type=str, default="config/minnafx.yaml", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--symbols", type=str, default="USD/JPY,EUR/JPY,GBP/JPY", help="é€šè²¨ãƒšã‚¢ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
    parser.add_argument("--start-date", type=str, required=True, help="é–‹å§‹æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--end-date", type=str, required=True, help="çµ‚äº†æ—¥ (YYYY-MM-DD)")
    parser.add_argument("--equity", type=float, default=100000.0, help="åˆæœŸè³‡é‡‘")
    parser.add_argument("--risk-pct", type=float, default=0.005, help="ãƒªã‚¹ã‚¯ç‡")
    parser.add_argument("--atr-mult", type=float, default=1.2, help="ATRå€ç‡")
    parser.add_argument("--tp1-r", type=float, default=1.2, help="TP1ã®Rå€æ•°")
    parser.add_argument("--tp2-r", type=float, default=2.4, help="TP2ã®Rå€æ•°ï¼ˆFIXED_Rãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ä½¿ç”¨ï¼‰")
    parser.add_argument("--tp2-mode", type=str, default="FIXED_R", choices=["FIXED_R", "STRUCTURE"], help="TP2è¨ˆç®—ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--tp2-lookback-days", type=int, default=20, help="æ§‹é€ å‹TP2ã®æ¤œç´¢æœŸé–“ï¼ˆæ—¥æ•°ï¼‰")
    parser.add_argument("--output", type=str, default="data/results_v4", help="å‡ºåŠ›ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--run-id", type=str, default=None, help="å®Ÿè¡ŒIDï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰")
    parser.add_argument("--use-daylight", action="store_true", help="ç±³å›½å¤æ™‚é–“é©ç”¨")

    args = parser.parse_args()

    # run_idç”Ÿæˆï¼ˆçœç•¥æ™‚ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
    if args.run_id is None:
        args.run_id = datetime.now().strftime("%Y%m%d_%H%M%S")

    # è¨­å®šèª­ã¿è¾¼ã¿
    config = load_broker_config(args.config)
    print(f"âœ… è¨­å®šèª­ã¿è¾¼ã¿: {args.config}")

    # API Keyï¼ˆå¿…é ˆï¼‰
    api_key = check_api_key(required=True)

    # é€šè²¨ãƒšã‚¢ãƒªã‚¹ãƒˆ
    symbols = [s.strip() for s in args.symbols.split(",")]

    print(f"\n{'='*60}")
    print(f"V4çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"{'='*60}")
    print(f"Run ID: {args.run_id}")
    print(f"æœŸé–“: {args.start_date} ~ {args.end_date}")
    print(f"é€šè²¨ãƒšã‚¢: {', '.join(symbols)}")
    print(f"åˆæœŸè³‡é‡‘: {args.equity:,.0f}å††")
    print(f"ãƒªã‚¹ã‚¯è¨­å®š: {args.risk_pct*100:.1f}%")
    tp2_desc = f"{args.tp2_mode}" if args.tp2_mode == "STRUCTURE" else f"{args.tp2_r}R"
    print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: ATR {args.atr_mult} Ã— TP1 {args.tp1_r}R Ã— TP2 {tp2_desc}")
    if args.tp2_mode == "STRUCTURE":
        print(f"  TP2æ§‹é€ å‹: æ—¥è¶³ã‚¹ã‚¤ãƒ³ã‚°ï¼ˆç›´è¿‘{args.tp2_lookback_days}æ—¥ã€æœ€å¤§{args.tp2_r}Rã‚­ãƒ£ãƒƒãƒ—ï¼‰")
    print(f"å‡ºåŠ›å…ˆ: {args.output}/{args.run_id}/")
    print(f"{'='*60}\n")

    for symbol in symbols:
        print(f"[{symbol}] ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

        try:
            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            trades, equity_df, stats = run_backtest_v4_integrated(
                symbol=symbol,
                start_date=args.start_date,
                end_date=args.end_date,
                config=config,
                api_key=api_key,
                initial_equity=args.equity,
                risk_pct=args.risk_pct,
                atr_multiplier=args.atr_mult,
                tp1_r=args.tp1_r,
                tp2_r=args.tp2_r,
                tp1_close_pct=0.5,
                use_cache=True,
                sl_priority=True,
                use_daylight=args.use_daylight,
                run_id=args.run_id,
                tp2_mode=args.tp2_mode,
                tp2_lookback_days=args.tp2_lookback_days
            )

            print(f"  âœ… å®Œäº†: {stats['executed_trades']}ãƒˆãƒ¬ãƒ¼ãƒ‰")
            print(f"     ã‚¹ã‚­ãƒƒãƒ—: {stats['skipped_signals']}ä»¶ " +
                  f"(ãƒ¡ãƒ³ãƒ† {stats['maintenance_skips']}, " +
                  f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ {stats['spread_filter_skips']}, " +
                  f"ã‚µã‚¤ã‚º {stats['position_size_skips']})")

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            metrics = calculate_metrics_v3(
                trades, args.equity, args.start_date, args.end_date
            )

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¡¨ç¤º
            print(f"     PF (net): {metrics['pf_net']:.2f}")
            print(f"     å‹ç‡: {metrics['win_rate']*100:.1f}%")
            print(f"     æç›Š (net): {metrics['total_pnl_net']:,.0f}å††")
            print(f"     æœ€å¤§DD: {metrics['max_drawdown_close_based']*100:.2f}%")
            print(f"     ãƒªã‚¹ã‚¯é•å: {metrics['risk_violations_count']}ä»¶")

            # violations=0ç¢ºèª
            if metrics['risk_violations_count'] > 0:
                print(f"     âš ï¸ WARNING: ãƒªã‚¹ã‚¯é•åãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            else:
                print(f"     âœ… Violations=0 ç¢ºèª")

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_dir = Path(args.output) / args.run_id / symbol.replace("/", "_")
            output_dir.mkdir(parents=True, exist_ok=True)

            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            trades_df = trades_to_dataframe(trades)
            fills_df = fills_to_dataframe(trades)

            trades_df.to_csv(output_dir / "trades.csv", index=False)
            fills_df.to_csv(output_dir / "fills.csv", index=False)
            equity_df.to_csv(output_dir / "equity_curve.csv", index=False)

            # ã‚¹ã‚­ãƒƒãƒ—è¨˜éŒ²
            if stats['skipped_details']:
                skipped_df = pd.DataFrame(stats['skipped_details'])
                skipped_df.to_csv(output_dir / "skipped_signals.csv", index=False)

            # ã‚µãƒãƒªãƒ¼ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ + çµ±è¨ˆï¼‰
            summary = {
                **metrics,
                "run_id": args.run_id,
                "symbol": symbol,
                "start_date": args.start_date,
                "end_date": args.end_date,
                "config_file": args.config,
                "parameters": {
                    "initial_equity": args.equity,
                    "risk_pct": args.risk_pct,
                    "atr_multiplier": args.atr_mult,
                    "tp1_r": args.tp1_r,
                    "tp2_r": args.tp2_r,
                },
                "stats": stats
            }

            with open(output_dir / "summary.json", "w") as f:
                json.dump(summary, f, indent=2, default=str)

            print(f"     ğŸ“ å‡ºåŠ›: {output_dir}/\n")

        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}\n")
            import traceback
            traceback.print_exc()

    print(f"\n{'='*60}")
    print(f"âœ… V4çµ±åˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"{'='*60}")
    print(f"å‡ºåŠ›: {args.output}/{args.run_id}/")
    print(f"\nå„é€šè²¨ãƒšã‚¢ã®è©³ç´°:")
    for symbol in symbols:
        output_dir = Path(args.output) / args.run_id / symbol.replace("/", "_")
        if (output_dir / "summary.json").exists():
            print(f"  - {symbol}: {output_dir}/")


if __name__ == "__main__":
    main()
