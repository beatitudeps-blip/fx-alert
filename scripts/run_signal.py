"""
FXã‚·ã‚°ãƒŠãƒ«æ¤œå‡ºâ†’LINEé€šçŸ¥ï¼ˆã¿ã‚“ãªã®FXå®Ÿé‹ç”¨å¯¾å¿œï¼‰

å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¢ºå®šè¶³ã®ã¿ã§ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šã—ã€
config/minnafx.yamlã«åŸºã¥ã„ãŸã‚³ã‚¹ãƒˆ/ãƒªã‚¹ã‚¯ç®¡ç†ã§é€šçŸ¥ã‚’ç”Ÿæˆ

Usage:
    python3 scripts/run_signal.py --dry-run --symbols USD/JPY,EUR/JPY,GBP/JPY
    python3 scripts/run_signal.py --send --symbols EUR/JPY --equity 100000
"""
import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo
import pandas as pd
import requests

# ãƒ‘ã‚¹è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.env_check import load_dotenv_if_exists, check_api_key, check_line_credentials
from src.config_loader import load_broker_config
from src.broker_costs.minnafx import MinnafxCostModel
from src.position_sizing import calculate_position_size_strict, units_to_lots
from src.notify_line import LineNotifier

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
load_dotenv_if_exists()


# ==================== ãƒ‡ãƒ¼ã‚¿å–å¾— ====================

def fetch_data(symbol: str, interval: str, outputsize: int, api_key: str) -> pd.DataFrame:
    """Twelve Data APIã‹ã‚‰OHLCãƒ‡ãƒ¼ã‚¿å–å¾—"""
    url = "https://api.twelvedata.com/time_series"
    params = {
        "symbol": symbol,
        "interval": interval,
        "outputsize": outputsize,
        "apikey": api_key,
    }
    r = requests.get(url, params=params, timeout=25)
    r.raise_for_status()
    data = r.json()

    if "values" not in data:
        raise ValueError(f"API error: {data}")

    df = pd.DataFrame(data["values"])
    df["datetime"] = pd.to_datetime(df["datetime"])
    for col in ["open", "high", "low", "close"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    df = df.dropna(subset=["open", "high", "low", "close"]).sort_values("datetime").reset_index(drop=True)
    return df


# ==================== ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¨ˆç®— ====================

def calculate_ema(series: pd.Series, period: int) -> pd.Series:
    """EMAè¨ˆç®—"""
    return series.ewm(span=period, adjust=False).mean()


def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """ATRè¨ˆç®—"""
    prev_close = df["close"].shift(1)
    tr1 = df["high"] - df["low"]
    tr2 = (df["high"] - prev_close).abs()
    tr3 = (df["low"] - prev_close).abs()
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    return tr.ewm(alpha=1 / period, adjust=False).mean()


# ==================== ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š ====================

def is_bullish_engulfing(prev_row: pd.Series, curr_row: pd.Series) -> bool:
    """Bullish Engulfingãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š"""
    prev_bearish = prev_row["close"] < prev_row["open"]
    curr_bullish = curr_row["close"] > curr_row["open"]
    engulfing = (
        curr_row["close"] >= prev_row["open"] and
        curr_row["open"] <= prev_row["close"]
    )
    return prev_bearish and curr_bullish and engulfing


def is_bullish_hammer(row: pd.Series) -> bool:
    """Hammerãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®šï¼ˆé•·ã„ä¸‹ãƒ’ã‚²ï¼‰"""
    body = abs(row["close"] - row["open"])
    if body <= 0:
        return False

    lower_wick = min(row["open"], row["close"]) - row["low"]
    upper_wick = row["high"] - max(row["open"], row["close"])

    return (
        row["close"] > row["open"] and
        lower_wick >= body * 1.5 and
        lower_wick >= upper_wick * 2.0
    )


def is_bearish_engulfing(prev_row: pd.Series, curr_row: pd.Series) -> bool:
    """Bearish Engulfingãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®š"""
    prev_bullish = prev_row["close"] > prev_row["open"]
    curr_bearish = curr_row["close"] < curr_row["open"]
    engulfing = (
        curr_row["close"] <= prev_row["open"] and
        curr_row["open"] >= prev_row["close"]
    )
    return prev_bullish and curr_bearish and engulfing


def is_bearish_shooting_star(row: pd.Series) -> bool:
    """Shooting Starãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®šï¼ˆé•·ã„ä¸Šãƒ’ã‚²ï¼‰"""
    body = abs(row["close"] - row["open"])
    if body <= 0:
        return False

    upper_wick = row["high"] - max(row["open"], row["close"])
    lower_wick = min(row["open"], row["close"]) - row["low"]

    return (
        row["close"] < row["open"] and
        upper_wick >= body * 1.5 and
        upper_wick >= lower_wick * 2.0
    )


# ==================== ç’°å¢ƒãƒã‚§ãƒƒã‚¯ ====================

def check_daily_environment(d1: pd.DataFrame) -> dict:
    """æ—¥è¶³ç’°å¢ƒãƒã‚§ãƒƒã‚¯ï¼ˆEMA20ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰"""
    d1 = d1.copy()
    d1["ema20"] = calculate_ema(d1["close"], 20)

    # ç¢ºå®šè¶³ã®ã¿ï¼ˆæœ€æ–°è¶³ã¯å½¢æˆä¸­ãªã®ã§é™¤å¤–ï¼‰
    if len(d1) < 3:
        return {"ok": False, "reason": "æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}

    latest = d1.iloc[-2]  # 1ã¤å‰ã®ç¢ºå®šè¶³
    prev = d1.iloc[-3]

    # close > EMA20 ã‹ã¤ EMA20ä¸Šå‘ã
    is_uptrend = latest["close"] > latest["ema20"] and latest["ema20"] > prev["ema20"]
    is_downtrend = latest["close"] < latest["ema20"] and latest["ema20"] < prev["ema20"]

    if is_uptrend:
        return {"ok": True, "direction": "LONG", "ema20": latest["ema20"]}
    elif is_downtrend:
        return {"ok": True, "direction": "SHORT", "ema20": latest["ema20"]}
    else:
        return {"ok": False, "reason": "æ—¥è¶³ç’°å¢ƒNGï¼ˆãƒ¬ãƒ³ã‚¸ï¼‰"}


# ==================== ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š ====================

def check_signal(h4: pd.DataFrame, d1: pd.DataFrame, atr_mult: float = 1.2) -> dict:
    """ã‚·ã‚°ãƒŠãƒ«åˆ¤å®šï¼ˆç¢ºå®šè¶³ã®ã¿ï¼‰"""
    # æ—¥è¶³ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    env = check_daily_environment(d1)
    if not env["ok"]:
        return {"signal": False, "reason": env["reason"]}

    # 4Hè¶³ã®è¨ˆç®—
    h4 = h4.copy()
    h4["ema20"] = calculate_ema(h4["close"], 20)
    h4["atr14"] = calculate_atr(h4, 14)

    # ç¢ºå®šè¶³ã®ã¿ï¼ˆæœ€æ–°è¶³ã¯å½¢æˆä¸­ãªã®ã§é™¤å¤–ï¼‰
    if len(h4) < 3:
        return {"signal": False, "reason": "4Hè¶³ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}

    latest = h4.iloc[-2]  # 1ã¤å‰ã®ç¢ºå®šè¶³ï¼ˆã‚·ã‚°ãƒŠãƒ«è¶³ï¼‰
    prev = h4.iloc[-3]

    # EMAã‚¿ãƒƒãƒãƒã‚§ãƒƒã‚¯
    touch_ema = latest["low"] <= latest["ema20"] <= latest["high"]
    if not touch_ema:
        return {"signal": False, "reason": "EMAã‚¿ãƒƒãƒãªã—"}

    # æ–¹å‘åˆ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
    if env["direction"] == "LONG":
        is_engulfing = is_bullish_engulfing(prev, latest)
        is_hammer = is_bullish_hammer(latest)

        if not (is_engulfing or is_hammer):
            return {"signal": False, "reason": "LONGãƒˆãƒªã‚¬ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—"}

        pattern = "Bullish Engulfing" if is_engulfing else "Bullish Hammer"
        side = "LONG"

    else:  # SHORT
        is_engulfing = is_bearish_engulfing(prev, latest)
        is_shooting = is_bearish_shooting_star(latest)

        if not (is_engulfing or is_shooting):
            return {"signal": False, "reason": "SHORTãƒˆãƒªã‚¬ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—"}

        pattern = "Bearish Engulfing" if is_engulfing else "Shooting Star"
        side = "SHORT"

    atr = latest["atr14"]

    # SL/TPè¨ˆç®—ï¼ˆä»²å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
    entry_mid = latest["close"]

    if side == "LONG":
        sl_mid = entry_mid - (atr * atr_mult)
        tp1_mid = entry_mid + (abs(entry_mid - sl_mid) * 1.2)  # 1.2R
        tp2_mid = entry_mid + (abs(entry_mid - sl_mid) * 2.4)  # 2.4R
    else:  # SHORT
        sl_mid = entry_mid + (atr * atr_mult)
        tp1_mid = entry_mid - (abs(entry_mid - sl_mid) * 1.2)
        tp2_mid = entry_mid - (abs(entry_mid - sl_mid) * 2.4)

    return {
        "signal": True,
        "side": side,
        "pattern": pattern,
        "signal_dt": latest["datetime"],
        "entry_mid": entry_mid,
        "sl_mid": sl_mid,
        "tp1_mid": tp1_mid,
        "tp2_mid": tp2_mid,
        "atr": atr,
        "ema20": latest["ema20"],
        "daily_ema20": env["ema20"]
    }


# ==================== ãƒ¡ã‚¤ãƒ³å‡¦ç† ====================

def main():
    parser = argparse.ArgumentParser(description="FXã‚·ã‚°ãƒŠãƒ«æ¤œå‡ºâ†’LINEé€šçŸ¥")
    parser.add_argument("--config", type=str, default="config/minnafx.yaml", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser.add_argument("--symbols", type=str, default="USD/JPY,EUR/JPY,GBP/JPY", help="é€šè²¨ãƒšã‚¢ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰")
    parser.add_argument("--equity", type=float, default=100000.0, help="å£åº§æ®‹é«˜ï¼ˆJPYï¼‰")
    parser.add_argument("--risk-pct", type=float, default=0.005, help="ãƒªã‚¹ã‚¯ç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.005=0.5%ï¼‰")
    parser.add_argument("--atr-mult", type=float, default=1.2, help="SLè·é›¢ï¼ˆATR Ã— atr_multï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="æ¨™æº–å‡ºåŠ›ã®ã¿ï¼ˆLINEé€ä¿¡ã—ãªã„ï¼‰")
    parser.add_argument("--send", action="store_true", help="LINEé€ä¿¡ã™ã‚‹")
    parser.add_argument("--entry-mode", type=str, default="NEXT_OPEN_MARKET", choices=["NEXT_OPEN_MARKET", "BREAKOUT_STOP"])
    parser.add_argument("--log-level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])

    args = parser.parse_args()

    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    logger = logging.getLogger(__name__)

    # è¨­å®šèª­ã¿è¾¼ã¿
    try:
        config = load_broker_config(args.config)
        logger.info(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {args.config}")
    except Exception as e:
        logger.error(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # Twelve Data API Keyï¼ˆå¿…é ˆï¼‰
    api_key = check_api_key(required=True)

    # LINEèªè¨¼æƒ…å ±ï¼ˆ--sendã®å ´åˆã®ã¿å¿…é ˆï¼‰
    if args.send:
        line_token, line_user_id = check_line_credentials(required=True)
    else:
        line_token = "dummy_token"
        line_user_id = "dummy_user"

    # ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
    cost_model = MinnafxCostModel(config)

    # LINEé€šçŸ¥
    notifier = LineNotifier(
        line_token=line_token,
        line_user_id=line_user_id,
        config=config,
        state_file="data/notification_state.json"
    )

    # é€šè²¨ãƒšã‚¢ãƒªã‚¹ãƒˆ
    symbols = [s.strip() for s in args.symbols.split(",")]

    logger.info(f"=== FXã‚·ã‚°ãƒŠãƒ«æ¤œå‡ºé–‹å§‹ ===")
    logger.info(f"å¯¾è±¡é€šè²¨: {', '.join(symbols)}")
    logger.info(f"å£åº§æ®‹é«˜: {args.equity:,.0f}å††")
    logger.info(f"ãƒªã‚¹ã‚¯è¨­å®š: {args.risk_pct*100:.1f}%")
    logger.info(f"ãƒ¢ãƒ¼ãƒ‰: {'dry-runï¼ˆæ¨™æº–å‡ºåŠ›ã®ã¿ï¼‰' if args.dry_run else 'LINEé€ä¿¡ï¼ˆ1é€šã«ã¾ã¨ã‚ã‚‹ï¼‰'}")

    # çµæœåé›†ç”¨ï¼ˆ3é€šè²¨åˆ†ã‚’ã¾ã¨ã‚ã‚‹ï¼‰
    results = []
    bar_dt = None  # ç¢ºå®š4Hè¶³æ™‚åˆ»ï¼ˆå…¨é€šè²¨ã§å…±é€šï¼‰

    for symbol in symbols:
        logger.info(f"\n{'='*60}")
        logger.info(f"[{symbol}] ãƒã‚§ãƒƒã‚¯ä¸­...")

        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            h4 = fetch_data(symbol, "4h", 200, api_key)
            d1 = fetch_data(symbol, "1day", 120, api_key)
            logger.info(f"  ãƒ‡ãƒ¼ã‚¿å–å¾—: 4H {len(h4)}æœ¬, æ—¥è¶³ {len(d1)}æœ¬")

            # ã‚·ã‚°ãƒŠãƒ«åˆ¤å®š
            result = check_signal(h4, d1, args.atr_mult)

            # ç¢ºå®š4Hè¶³æ™‚åˆ»ã‚’å–å¾—ï¼ˆå…¨é€šè²¨ã§å…±é€šï¼‰
            if len(h4) >= 2:
                latest_bar = h4.iloc[-2]  # ç¢ºå®šè¶³
                bar_dt_tmp = latest_bar["datetime"]
                if bar_dt_tmp.tzinfo is None:
                    bar_dt_tmp = bar_dt_tmp.tz_localize("UTC").tz_convert(ZoneInfo("Asia/Tokyo"))
                else:
                    bar_dt_tmp = bar_dt_tmp.astimezone(ZoneInfo("Asia/Tokyo"))

                if bar_dt is None:
                    bar_dt = bar_dt_tmp

            if not result["signal"]:
                logger.info(f"  âŒ ã‚·ã‚°ãƒŠãƒ«ãªã—: {result['reason']}")
                # è¦‹é€ã‚Šçµæœã‚’è¿½åŠ 
                results.append({
                    "symbol": symbol,
                    "status": "SKIP",
                    "reason": result["reason"]
                })
                continue

            logger.info(f"  âœ… ã‚·ã‚°ãƒŠãƒ«æ¤œå‡º: {result['side']} {result['pattern']}")

            # æ¬¡è¶³æ™‚åˆ»ï¼ˆ4Hè¶³ãªã‚‰+4æ™‚é–“ï¼‰
            next_dt = result["signal_dt"] + pd.Timedelta(hours=4)

            # JSTã«å¤‰æ›
            if next_dt.tzinfo is None:
                next_dt = next_dt.tz_localize("UTC").tz_convert(ZoneInfo("Asia/Tokyo"))
            else:
                next_dt = next_dt.astimezone(ZoneInfo("Asia/Tokyo"))

            # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚é–“ãƒã‚§ãƒƒã‚¯
            if not cost_model.is_tradable(next_dt):
                logger.warning(f"  âš ï¸ è¦‹é€ã‚Š: ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚é–“ä¸­ï¼ˆ{next_dt.strftime('%Y-%m-%d %H:%M JST')}ï¼‰")
                results.append({
                    "symbol": symbol,
                    "status": "SKIP",
                    "reason": f"ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ™‚é–“ä¸­ï¼ˆ{next_dt.strftime('%H:%M JST')}ï¼‰"
                })
                continue

            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            should_skip, skip_reason = cost_model.should_skip_entry(symbol, next_dt)
            if should_skip:
                logger.warning(f"  âš ï¸ è¦‹é€ã‚Š: {skip_reason}")
                results.append({
                    "symbol": symbol,
                    "status": "SKIP",
                    "reason": skip_reason
                })
                continue

            # å®Ÿè¡Œä¾¡æ ¼è¨ˆç®—
            entry_exec = cost_model.calculate_execution_price(
                result["entry_mid"], result["side"], symbol, next_dt
            )
            sl_exec = cost_model.calculate_exit_price(
                result["sl_mid"], result["side"], symbol, next_dt
            )

            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚¸ãƒ³ã‚°ï¼ˆå³æ ¼0.5%ï¼‰
            units, actual_risk, is_valid = calculate_position_size_strict(
                args.equity, entry_exec, sl_exec, args.risk_pct, config, symbol
            )

            if not is_valid:
                logger.warning(f"  âš ï¸ è¦‹é€ã‚Š: ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºè¨ˆç®—ä¸å¯ï¼ˆæœ€å°ãƒ­ãƒƒãƒˆæœªæº€ï¼‰")
                results.append({
                    "symbol": symbol,
                    "status": "SKIP",
                    "reason": "ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºè¨ˆç®—ä¸å¯ï¼ˆæœ€å°ãƒ­ãƒƒãƒˆæœªæº€ï¼‰"
                })
                continue

            lots = units_to_lots(units, config, symbol)

            # Violations=0 ç¢ºèª
            max_allowed_risk = args.equity * args.risk_pct
            if actual_risk > max_allowed_risk:
                logger.error(f"  âŒ CRITICAL: ãƒªã‚¹ã‚¯è¶…éæ¤œå‡ºï¼ˆ{actual_risk:.0f}å†† > {max_allowed_risk:.0f}å††ï¼‰")
                results.append({
                    "symbol": symbol,
                    "status": "SKIP",
                    "reason": f"ãƒªã‚¹ã‚¯è¶…éï¼ˆ{actual_risk:.0f}å†† > {max_allowed_risk:.0f}å††ï¼‰"
                })
                continue

            logger.info(f"  æ¨å¥¨æ•°é‡: {lots:.1f}Lot ({units:,.0f}é€šè²¨), ãƒªã‚¹ã‚¯: {actual_risk:.0f}å††")

            # ã‚·ã‚°ãƒŠãƒ«çµæœã‚’è¿½åŠ 
            results.append({
                "symbol": symbol,
                "status": "SIGNAL",
                "side": result["side"],
                "pattern": result["pattern"],
                "entry_price_mid": result["entry_mid"],
                "sl_price_mid": result["sl_mid"],
                "tp1_price_mid": result["tp1_mid"],
                "tp2_price_mid": result["tp2_mid"],
                "atr": result["atr"],
                "ema20": result["ema20"],
                "entry_mode": args.entry_mode,
                "exit_config": {
                    "tp1_close_pct": 0.5,
                    "move_to_be": True,
                    "be_buffer_pips": 0.0,
                    "tp2_mode": "FIXED_R",
                    "time_stop": None,
                    "daily_flip_exit": False
                }
            })

        except Exception as e:
            logger.error(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            results.append({
                "symbol": symbol,
                "status": "SKIP",
                "reason": f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
            })

    # ãƒãƒƒãƒé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆï¼ˆ3é€šè²¨ã‚’1é€šã«ã¾ã¨ã‚ã‚‹ï¼‰
    logger.info(f"\n{'='*60}")

    if bar_dt is None:
        logger.error("âŒ ç¢ºå®š4Hè¶³æ™‚åˆ»ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return

    run_dt = datetime.now(ZoneInfo("Asia/Tokyo"))

    # âš ï¸ é‡è¦: bar_dtã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆcronè¨­å®šã®å‚è€ƒã«ã™ã‚‹ï¼‰
    logger.info(f"ç¢ºå®š4Hè¶³æ™‚åˆ»ï¼ˆbar_dtï¼‰: {bar_dt.strftime('%Y-%m-%d %H:%M JST')}")
    logger.info(f"æ¬¡è¶³å§‹å€¤: {(bar_dt + pd.Timedelta(hours=4)).strftime('%Y-%m-%d %H:%M JST')}")
    logger.info(f"ğŸ’¡ cronè¨­å®šã®ãƒ’ãƒ³ãƒˆ: Twelve Data APIã¯é€šå¸¸ JST 00:00, 04:00, 08:00... â†’ cronã€Œ5 0,4,8,12,16,20 * * *ã€")

    batch_msg = notifier.create_batch_message(
        run_dt=run_dt,
        bar_dt=bar_dt,
        results=results,
        equity_jpy=args.equity,
        risk_pct=args.risk_pct
    )

    if batch_msg is None:
        logger.info("âš ï¸ åŒä¸€4Hãƒãƒ¼ã§æ—¢ã«é€ä¿¡æ¸ˆã¿ï¼ˆbar_dtãƒ‡ãƒ‡ãƒ¥ãƒ¼ãƒ—ï¼‰")
        return

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    signal_count = sum(1 for r in results if r["status"] == "SIGNAL")
    skip_count = sum(1 for r in results if r["status"] == "SKIP")
    logger.info(f"çµæœ: ã‚·ã‚°ãƒŠãƒ« {signal_count}é€šè²¨ã€è¦‹é€ã‚Š {skip_count}é€šè²¨")

    # é€šçŸ¥å‡ºåŠ›/é€ä¿¡
    print(f"\n{'='*80}")
    print("ğŸ“Š ãƒãƒƒãƒé€šçŸ¥ï¼ˆ3é€šè²¨ã¾ã¨ã‚ï¼‰")
    print(f"{'='*80}")
    print(batch_msg)

    if args.send:
        success = notifier.send_line(batch_msg)
        if success:
            logger.info("âœ… LINEé€ä¿¡å®Œäº†ï¼ˆ1é€šï¼‰")
        else:
            logger.error("âŒ LINEé€ä¿¡å¤±æ•—")
    elif args.dry_run:
        logger.info("\nğŸ“ dry-runãƒ¢ãƒ¼ãƒ‰: LINEé€ä¿¡ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸ")

    logger.info(f"\næ¬¡å›é€šçŸ¥: æ¬¡ã®4Hè¶³ç¢ºå®šå¾Œï¼ˆbar_dt: {bar_dt.strftime('%Y-%m-%d %H:%M JST')}ï¼‰")


if __name__ == "__main__":
    main()
